---
title: "trackingC.Rmd"
author: "Leeya Pressburger"
date: "2/3/2022"
output:
  bookdown::html_document2:
    fig_caption: yes
    number_sections: yes
    toc: true
    toc_depth: 2
    toc_float: true
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Setup

Load necessary packages, read in an ini file and initiate core, and set seed for reproducibility.

```{r intro, warning=FALSE, message=FALSE}
library(hector)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(relaimpo)
library(GGally)
library(bookdown)

theme_set(theme_light())

# Read in ini file, initiate new core
ssp245 <- system.file("input/hector_ssp245.ini", package = "hector") 
core <- newcore(ssp245)

# Set random number generator to allow for reproducibility 
set.seed(10)

```

# Create dataset

```{r params}
# Create runlist of parameters of interest

# Function to access lognorm parameters with a desired mean and standard deviation
# Reference: https://msalganik.wordpress.com/2017/01/21/making-sense-of-the-rlnorm-function-in-r/
lognorm <- function(m, sd){
  location <- log(m^2 / sqrt(sd^2 + m^2))
  shape <- sqrt(log(1+ (sd^2 / m^2)))
  v <- c(location, shape)
}

N_RUNS <- 25

# We use GitHub Actions to make sure this RMarkdown knits successfully
# But if running there, only do a small number of Hector simulations
if(Sys.getenv("CI") == "true") {
  N_RUNS <- 100
}

# Runlist contains run number, parameter, and a random distribution
runlist <- tibble(
  run_number = 1:N_RUNS,
  "BETA" = rnorm(N_RUNS, mean = 0.54, sd = 0.03),
  "Q10_RH" = rlnorm(N_RUNS, lognorm(2, 1.0)[1], lognorm(2, 1.0)[2]),
  # Hector default - note joint with diffusivity
  "ECS" = rlnorm(N_RUNS, lognorm(3, 1.0)[1], lognorm(3, 1.0)[2]),
  "NPP_FLUX0" = rnorm(N_RUNS, mean = 56.2, sd = 5.62),
  # Hector default
  "AERO_SCALE" = rnorm(N_RUNS, mean = 1.0, sd = 0.1),
  # Hector default - note joint with ECS
  "DIFFUSIVITY" = rnorm(N_RUNS, mean = 2.3, sd = 0.23),
)

# Name and units of parameters
name_vector <- c("BETA" = BETA(), "Q10_RH" = Q10_RH(), 
                 "ECS" = ECS(), "NPP_FLUX0" = NPP_FLUX0(),
                 "AERO_SCALE" = AERO_SCALE(), "DIFFUSIVITY" = DIFFUSIVITY()
                 )

units_vector <- c("BETA" = "(unitless)", "Q10_RH" = "(unitless)", 
                  "ECS" = "degC", "NPP_FLUX0" = "Pg C/yr",
                  "AERO_SCALE" = "(unitless)", "DIFFUSIVITY" = "cm2/s"
                  )
```

# Run the model

```{r functions, cache=TRUE, message=FALSE}

run_hector <- function(pdata, c) {
  # Function to set multiple parameter values for Hector, run a core, and retrieve tracking data
  # pdata will be the runlist specified above and c is a newcore environment
  # For each parameter within each run, set its value and units
  for(p in colnames(pdata)) {
    message("\tSetting ", p)
    setvar(c, NA, do.call(p, list()), pdata[p][[1]], units_vector[p])
  }
  # Set a tracking data, reset and run core
  setvar(c, NA, TRACKING_DATE(), 1950, NA)
  reset(c)
  run(c)
  # Access and save tracking data
  tdata <- get_tracking_data(c)
  tdata %>% filter(year %in% c(2000:2200))
}

# Run function for each row of the runlist
# Create destination list
out <- list()

# List for the rows that error
errors <- list()

# For each row of the runlist, apply the run_hector() function
# If there is an error, record which row triggers the error, and skip to the next row

# Record start time 
start <- Sys.time()

for(row in seq_len(nrow(runlist))) {
  message(row, "/", nrow(runlist))
  outp <- try(run_hector(runlist[row,][-1], core))
  if(class(outp) == "try-error") { 
    # if there is an error, record row numbers that error
    errors[[row]] <- runlist$run_number[[row]]
  } else {
    out[[runlist$run_number[row]]] <- outp
  }}  

# Compute difference in time between start and after loop is run
tm <- difftime(Sys.time(), start, units = "secs") %>% round(1)
```

Running took `r tm` seconds or `r tm/N_RUNS` s/job.

# Process data

``` {r data}
# Get output dataframe
output <- bind_rows(out, .id = "run_number") %>% as_tibble()

# Can left join with runlist to get param values
# Make sure data is same class
output$run_number <- as.integer(output$run_number)
output <- left_join(output, runlist, by = "run_number")

# If there are over 100 observations per time point, we want to use slice_sample() to randomly select rows to plot.
# Pull random run numbers from the runlist and filter output by random runs
max_display <- slice_sample(runlist, n = 100)
output_slice <- filter(output, run_number %in% max_display$run_number)

```

# Data visualization

The following sections contain tentative figures in the order they would appear
in a manuscript. 

# Parameters and PDFS

``` {r params-PDFs, fig.cap = " Probability densities of each parameter"}
# Density plot to visualize distribution
## TO DO make graphs look nice

plot(density(runlist[["BETA"]]))

plot(density(runlist[["Q10_RH"]]))

plot(density(runlist[["ECS"]]))

plot(density(runlist[["NPP_FLUX0"]]))

plot(density(runlist[["AERO_SCALE"]]))

plot(density(runlist[["DIFFUSIVITY"]]))
```

# Hector output graphs

``` {r atmosphere-by-source, fig.cap = " Fraction of CO2 in the atmosphere by source pool"}
# This code just looks at the atmosphere pool
atmos <- output_slice %>%
  filter(pool_name == "atmos_c")

# This plot looks at source fraction by source pool in the atmosphere as well as the median run.
ggplot(atmos, aes(year, source_fraction, color = as.factor(run_number), group = run_number)) +
  geom_line(size = 0.5, show.legend = FALSE) +
  facet_wrap(~source_name, scales = "free") +
  labs(x = "Year",
       y = "Source fraction") +
  scale_color_grey(start = 0.7, end = 0.7) +
  stat_summary(color = "black",
               fun = median, 
               geom = "line", 
               group = "run_number",
               size = 0.7)

```

``` {r coeff-var, fig.cap = " Coefficients of variability for each source in the atmosphere over time"}
# Compute coefficient of variability for each source in the atmosphere pool
atmos_cv <- atmos %>%
  group_by(year, source_name) %>%
  mutate(sdev = sd(source_fraction),
         mean = mean(source_fraction),
         cv = sdev / mean)

# Plot the coefficient of variability for each source in atmosphere pool over time
ggplot(atmos_cv, aes(year, cv, group = source_name, color = source_name)) +
  geom_line() +
  scale_color_viridis_d() +
  # Could add facets to look at variability, but more useful to compare CV
  #facet_wrap(~source_name, scales = "free") +
  labs(x = "Source fraction",
       y = "CV",
       title = "Coefficients of variability by source in the atmosphere pool")

```

``` {r earthc-in-atmos, fig.cap = " Source of carbon in the atmosphere from fossil fuel over time"}
# This chunk looks at the atmosphere pool with just one source (earth_c) 
# and plots source fraction over time with a mean and confidence interval

ff <- atmos %>% 
  filter(source_name == "earth_c") %>%
  group_by(year) %>%
  summarize(sf_sd = sd(source_fraction), 
            sf_min = min(source_fraction),
            sf_max = max(source_fraction),
            sf_median = median(source_fraction))

ggplot(ff, aes(year)) +
  geom_line(aes(y = sf_median)) +
  geom_ribbon(aes(ymin = sf_min, ymax = sf_max), alpha = 0.2) +
  geom_ribbon(aes(ymin = sf_median - sf_sd, ymax = sf_median + sf_sd), alpha = 0.2) +
  labs(x = "Year",
       y = "Source fraction")
```

# Where does carbon end up?

```{r destination, fig.cap = " Final destination pool of human emissions"}
# Where does carbon end up?
# We have pool_name, source_name, source_fraction
# Step 1: compute source_quantity = pool_value * source_fraction
# Step 2: for each year and source_name, compute destination_fraction
# group_by(year, source_name) %>% mutate(destination_fraction = source_quantity / sum(source_quantity))

destination <- output_slice %>%
  filter(source_name == "earth_c", pool_name != "earth_c") %>%
  mutate(source_quantity = pool_value * source_fraction) %>%
  group_by(year, run_number) %>%
  mutate(destination_percent = source_quantity / sum(source_quantity),
         destination_fraction = destination_percent / 100) %>% 
  ungroup()

# Just looking at particular runs
dest_runs <- filter(destination, run_number %in% c(1:30))

ggplot(dest_runs, aes(year, destination_percent, 
                   fill = pool_name)) +
  geom_area() +
  scale_fill_viridis_d() +
  facet_wrap(~run_number) +
  labs(x = "Year",
       y = "Destination fraction")

```

# All parameter combinations

```{r parameter-space, fig.cap = " Parameter correlation"}
# Single time point, pool, and source - exploring how the parameter space 
# is linked to output

single <- output %>%
  filter(pool_name == "atmos_c",
         source_name == "earth_c",
         year == 2100) %>% 
  mutate(sf = cut(source_fraction, 3))

## TO DO 
# Calculate the 9:14 dynamically, so when you add/remove params
# the graph adjusts automatically
# How to make this graph look better - viridis, one density plot
n <- length(name_vector)

ggpairs(single,
        columns = 9:(9 + (n-1)),
        aes(color = sf),
        upper = list(continuous = "blank"))
```

# What controls how much earth_c ends up in the atmosphere?

```{r relative-importance, fig.cap = " Relative importance of parameters over time"}
# Filter to just atmosphere pool, and remove unneeded columns
dest_e2a <- filter(destination, pool_name == "atmos_c")
dest_e2a_minimal <- dest_e2a[c("year", "destination_fraction", names(name_vector))]

# Function to calculate relative importance of parameters in
# explaining how much destination_fraction varies for a given
# year of data. This uses relaimpo::calc.relimp()
# See https://www.r-bloggers.com/2012/08/the-relative-importance-of-predictors-let-the-games-begin/
# for a useful primer, along with the calc.reimp help page
calc_relimp <- function(x) {
  yr <- x$year[1] # record year...
  x$year <- NULL # and drop year column
  # Fit model. The formula notation means "destination fraction as a
  # function of all other terms" (which is why we dropped year)
  m <- lm(destination_fraction ~ ., data = x)
  # Calculate relative importance metrics and extract 'lmg' results
  # 'lmg' is the R^2 contribution averaged over orderings among regressors;
  # should sum to one because we're using relative importances (rela=TRUE)
  relimp <- calc.relimp(m, type = "lmg", rela = TRUE)@lmg
  # Return a data frame: year, parameter, relative importance
  tibble(year = yr, param = names(relimp), value = relimp)
}

# Run calc_relimp above on each year's data
dest_split <- split(dest_e2a_minimal, dest_e2a_minimal$year)
relimp_out <- lapply(dest_split, FUN = calc_relimp) %>% 
  bind_rows()

# ...and plot!
ggplot(relimp_out, aes(year, value, fill = param)) + 
  geom_area() +
  coord_cartesian(expand = FALSE) +
  scale_fill_viridis_d(direction = -1) +
  labs(x = "Year",
       y = "Fraction of relative importance")
```
