---
title: "trackingC_setup"
author: "Leeya Pressburger"
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    fig_caption: yes
    number_sections: yes
    toc: true
    toc_depth: 2
    toc_float: true
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

# Introduction

## Science background

* We are pumping massive amounts of carbon dioxide into the atmosphere. 
Many studies have looked at the current dynamics of the C cycle, and/or 
long-term ultimate fate of anthropogenic CO~2~.

* There are many uncertainties surrounding the trend of airborne fraction
(thought of as how much anthropogenic CO~2~ remain in the atmosphere, though
see below), and more generally surrounding feedbacks and processes in the
earth system controlling the growth of atmospheric CO~2~ 
and thus radiative forcing.

* Simple climate models are a useful tool to understanding the short-term 
impacts of humans on the climate. In particular, the simple climate model 
Hector 3.0.0 incorporates a novel carbon tracking feature, allowing the user to 
trace the origins of CO~2~ as it moves through the Earth system.  

* Using this model allows us to understand how sensitive Hector is to changing 
parameters as well as determining the uncertainties in model projections.

## Goals

Using Hector v3.0.0 and its novel carbon tracking feature, we want to:  

* Understand the ultimate fate and distribution of anthropogenic CO~2~ and 
its controls.  

* Understand the uncertainties on the lifetime and fate of FFI CO~2~ emissions.  

* Understand the uncertainties on the trends/robustness of airborne fraction as
a metric for understanding how anthropogenic emissions influence the Earth system,
and how Earth system feedbacks influence airborne fraction.

* Quantify the likely distribution of the AF trend.

# Methods

## Definitions

* ƒATM~ffi~: the fraction of atmospheric CO~2~ derived from fossil fuel industrial emissions
* ƒFFI~atm~: the fraction of fossil fuel CO~2~ emissions residing in the atmosphere
* AF: airborne fraction, computed as $\Delta$ATM / $\Sigma$FFI over some time period

Note that while AF is commonly described as "the fraction of anthropogenic 
emissions which remain in the atmosphere" 
([source](https://gml.noaa.gov/co2conference/posters_pdf/jones1_poster.pdf)), 
the ratio above will not exactly be that, because in some circumstances earth 
system feedbacks will add to (or remove from) atmospheric CO~2~ as well. 
In addition, note that the formula above produces negative numbers if $\Delta$ATM < 0.


### R setup

Load necessary packages, read in an ini file and initiate core, and set seed for reproducibility.

```{r intro, warning=FALSE, message=FALSE}
library(hector)
library(relaimpo)
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(ggExtra)
library(GGally)
library(bookdown)
library(data.table) # for the speed of fwrite()

theme_set(theme_light())

source("trackingC_common.R")

# Set random number generator to allow for reproducibility 
set.seed(10)
```

### Create runlist of parameter draws

Currently, we are looking at seven Hector parameters: `BETA(), Q10_RH(), ECS(),
NPP_FLUX0(), AERO_SCALE(), DIFFUSIVITY(), and a LUC emissions scalar`. 
We created a runlist with `r SSP_runs[MAIN_SCENARIO]` random
draws in a normal (or lognormal, where applicable) distribution.

ECS (equilibrium climate sensitivity) and ocean heat diffusivity are 
notably correlated with each other, so we use a joint PDF for these.  

ECS is log-normally distributed, but we will transform it to fit a 
normal distribution by taking the log of the entire distribution.
If we do this, we can use MASS::mvrnorm() which saves us a LOT of work in
writing a custom rejection sampling routine...  

We will then transform the final values back to fit a lognormal distribution
by taking the exponential of our ECS values

```{r runlist}
# Create runlist of parameters of interest

# Function to access lognorm parameters with a desired mean and standard deviation
# Reference: https://msalganik.wordpress.com/2017/01/21/making-sense-of-the-rlnorm-function-in-r/
lognorm <- function(m, sd){
  mn <- log(m^2 / sqrt(sd^2 + m^2))
  stdev <- sqrt(log(1 + (sd^2 / m^2)))
  v <- c(mn, stdev)
}

# Function to create a tibble of random draws given a specified number to produce
generate_params <- function(run_numbers){
  runs <- length(run_numbers)
  tibble(
    run_number = run_numbers,
    # Keenan et al. (2021) (0.54, 0.03)
    "BETA" = rnorm(runs, mean = 0.5, sd = 0.1),
    
    # Davidson and Janssens (2006)
    "Q10_RH" = rlnorm(runs, lognorm(2, 1.0)[1], lognorm(2, 1.0)[2]),
    
    # Ito (2011)
    "NPP_FLUX0" = rnorm(runs, mean = 56.2, sd = 14.3),
    
    # Hector default
    "AERO_SCALE" = rnorm(runs, mean = 1.0, sd = 0.1),
    
    # Land use change emissions scaling parameter, to account for uncertainties in values for LUC
    # Friedlingstein et al 2021 state: 
    # Cumulative CO2 emissions from land-use changes (ELUC) for 1850-2020 were 200 ± 65 GtC...
    # ...large spread among individual estimates of 140 GtC (updated H&N2017), 270 GtC (BLUE),
    # and 195 GtC (OSCAR) for the three bookkeeping models and a similar wide estimate of 190 ± 60 GtC for the DGVMs
    # Cumulative LUC_EMISSIONS() in Hector from 1850 to 2020 total 168 GtC
    # We want to create a random distribution to scale our Hector emissions
    # to account for the large uncertainties
    # Our bounds for a reasonable scalar therefore are (270/168) and (140/168)
    # Or, 0.83 < x < 1.61 
    # The following distribution roughly aligns with the above criteria
    # Using a lognormal distribution because we do not want negative or near-zero values
    "LUC_SCALE" = rlnorm(runs, lognorm(1.3, 0.2)[1], lognorm(1.3, 0.2)[2])
  )
}

# Create a single runlist for all SSPs
# First create scenario identifier column (across all scenarios), 
# and then generate the run numbers 
scenarios <- rep(names(SSP_runs), SSP_runs) %>% as.vector()
runlist <- tibble(run_number = 1:sum(SSP_runs), ssp = scenarios)

# Next, create and join a parameter dataframe
param_sce <- generate_params(runlist$run_number)
runlist <- left_join(runlist, param_sce, by = "run_number")
```

``` {r joint-params, fig.cap = " The final joint distribution of ECS and diffusivity. The individual parameter distributions are shown on the x and y axes."}
# Joint PDF for ECS and diffusivity
# Sherwood et al (2020)
ecs_vals_lognorm <- rlnorm(nrow(runlist), 
                           lognorm(3.25, 0.65)[1], 
                           lognorm(3.25, 0.65)[2])
# Transform ECS distribution to log(distribution)
ecs_vals_to_norm <- log(ecs_vals_lognorm)
diffusion_vals <- rnorm(nrow(runlist), mean = 2.3, sd = 0.23)

DESIRED_PCOR <- -0.75  # ECS and diffusivity should be negatively correlated
# https://en.wikipedia.org/wiki/Covariance_and_correlation
# To calculate covariance from the desired correlation, multiply the 
# correlation by the square of the variance of each variable - the standard deviation
# https://web.stanford.edu/class/archive/cs/cs109/cs109.1178/lectureHandouts/150-covariance.pdf
desired_cov <- DESIRED_PCOR * sd(ecs_vals_to_norm) * sd(diffusion_vals)
# Set up the variance-covariance matrix
Sigma <- matrix(c(var(ecs_vals_to_norm), 
                  desired_cov, desired_cov, 
                  var(diffusion_vals)),
                2, 2)
# ...and generate values--twice as many as needed because we toss out
# negative ECS values below (see note above)
joint_vals <- MASS::mvrnorm(n = nrow(runlist) * 2,
                            c(mean(ecs_vals_to_norm),
                              mean(diffusion_vals)), Sigma)
colnames(joint_vals) <- c("ECS", "DIFFUSIVITY")
jv <- as_tibble(joint_vals)

# Filter and bind to the runlist
jv %>% 
  mutate(ECS = exp(ECS)) %>%
  filter(ECS > 0) %>% 
  sample_n(nrow(runlist)) %>%
  bind_cols(runlist, .) ->
  runlist

# Visualize the final joint distribution of ECS and DIFFUSIVITY
p <- ggplot(runlist, aes(ECS, DIFFUSIVITY)) + 
  geom_point(alpha = 0.2) + 
  geom_density_2d() +
  ggtitle("Joint distribution of ECS and DIFFUSIVITY")
ggExtra::ggMarginal(p, type = "histogram", alpha = 0.2)

```

``` {r log-dist, fig.cap = " Comparing the original, random, lognormal distribution for ECS with the final transformed version, the exponential of the log of ECS."}

# Visualize proper lognormal versus transformed distributions for ECS
tibble(lognorm = ecs_vals_lognorm, transformed = runlist$ECS) %>% 
  pivot_longer(everything()) %>% 
  ggplot(aes(value, fill = name)) + geom_density(alpha = 0.5) +
  ggtitle("Comparison of (proper) lognormal with transformed distribution for ECS")
```

## Run the model

Run the model and store outputs and tracking data.

```{r functions, cache=TRUE, message=FALSE}
run_hector <- function(pdata, c, sce) {
  
  # Function to set multiple parameter values for Hector, run a core, and retrieve tracking data
  # pdata will be the runlist specified above
  # c is a Hector newcore environment
  
  # For each parameter within each run, set its value and units
  message("\tSetting", appendLF = FALSE)
  for(p in colnames(pdata)) {
    message(" ", p, appendLF = FALSE)
    # If the parameter is a scaling constant, multiply and set scaled values
    if(p %in% scalar_vector) {
      setvar(c, luc$year, LUC_EMISSIONS(), (luc$value * pdata[p][[1]]), "Pg C/yr")
    } else {
      # Otherwise, simply set the value of the parameter itself
      setvar(c, NA, do.call(p, list()), pdata[p][[1]], units_vector[p])
    }
  }
  message("  ")
  # Set a tracking date, reset and run core
  setvar(c, NA, TRACKING_DATE(), TRACKING_START, NA)
  reset(c)
  run(c)
  # Access and save tracking data, model outputs
  out <- list()
  out$tdata <- get_tracking_data(c) %>% 
    filter(year %in% OUTPUT_YEARS, 
           # Save only emissions and their destinations or the atmosphere and its sources
           # to keep file size down
           source_name == "earth_c" | pool_name == "atmos_co2")
  out$results <- fetchvars(c, OUTPUT_YEARS, c("CO2_concentration", "RF_tot", "RF_CO2", "global_tas", "luc_emissions"))
  
  out$results$ssp <- sce
  out$tdata$ssp <- sce
  return(out)
}

# Run function for each row of the runlist

# Create destination list
out <- list()

# List for the rows that error
errors <- list()

# For each row of the runlist, apply the run_hector() function
# If there is an error, record which row triggers the error, and skip to the next

# Record start time 
start_time <- Sys.time()

for(s in names(SSP_files)) {
  # Filter runlist by scenario
  s_runlist <- runlist %>% filter(ssp == s)
  # Initiate new core, by scenario
  core <- newcore(SSP_files[[s]])
  # Run core, extract LUC emissions data for later multiplication by LUC_SCALE
  run(core)
  luc <- fetchvars(core, core$strtdate:core$enddate, LUC_EMISSIONS())
  
  for(row in seq_len(nrow(s_runlist))) {
    message(s, " ", row, "/", nrow(s_runlist))
    # Create unique ssp + run_number identifier for each row so that data 
    # does not get overwritten
    id <- paste0(s, "_", row)

    outp <- try(run_hector(s_runlist[row,][-c(1, 2)], core, s))
    if(class(outp) == "try-error") { 
      # if there is an error, record row numbers that error
      message("\tError!")
      errors[[id]] <- s_runlist$run_number[[row]]
    } else {
      # Save output by id
      out[[id]] <- outp
      # Add in run_number column - can no longer bind_rows() by run_number
      # because data is grouped by id
      out[[id]]$results$run_number <- s_runlist$run_number[[row]]
      out[[id]]$tdata$run_number <- s_runlist$run_number[[row]]
    }
  }
  shutdown(core)
}

# Compute difference in time between start and after loop is run
tm <- difftime(Sys.time(), start_time, units = "secs") %>% round(1)

# Collapse errors into a single vector
errors <- unlist(errors)
```

Doing `r nrow(runlist)` runs took `r tm` seconds 
or `r round(tm / (sum(SSP_runs)), 1)` s/job.

`r length(errors)` runs had errors.


## Process data

Get lists from above into nice dataframes.

```{r data}
if(!length(out)) {
  stop("No output data; probably no model runs were done because cache=TRUE?")
}

# Get output data frames
# First, access tracking data
tdata <- lapply(out, function(x) x$tdata)
trk_output <- bind_rows(tdata) %>% as_tibble

# Then, access model output data
results <- lapply(out, function(x) x$results)
model_output <- bind_rows(results) %>% as_tibble()

# Can left join with runlist to get param values
# Make sure data is same class
trk_output$run_number <- as.integer(trk_output$run_number)
trk_output <- left_join(trk_output, runlist, by = c("run_number", "ssp"))

model_output$run_number <- as.integer(model_output$run_number)
model_output <- left_join(model_output, runlist, by = c("run_number", "ssp"))
```

# Save outputs

```{r output-files}
fwrite(runlist, "./output_files/runlist.csv", row.names = FALSE)
fwrite(model_output, "./output_files/model_output.csv", row.names = FALSE)
fwrite(trk_output, "./output_files/trk_output.csv", row.names = FALSE)
```

# The End

```{r info}
sessionInfo()
```
